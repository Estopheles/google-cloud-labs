# Reporte T√©cnico: Introducci√≥n a SQL, BigQuery y Cloud SQL

**Laboratorio:** GSP281 - Google Cloud Skills Boost

**Autor:** Christhian Rodriguez

**Fecha:** 30 de Noviembre, 2025

## 1. Resumen Ejecutivo

En este laboratorio pr√°ctico se dise√±√≥ y ejecut√≥ un flujo de trabajo de **Ingenier√≠a de Datos (ETL)** b√°sico en Google Cloud Platform. El objetivo fue extraer datos masivos de un almac√©n de datos (BigQuery), transformarlos ligeramente y cargarlos en una base de datos relacional transaccional (Cloud SQL) para su gesti√≥n operativa. Se utilizaron servicios clave como **BigQuery**, **Cloud Storage** y **Cloud SQL**, interconectados mediante SQL y la consola de GCP.

## 2. Arquitectura y Tecnolog√≠as Utilizadas

### üß† Google BigQuery (El Cerebro Anal√≠tico)

Es un **Data Warehouse serverless** (sin servidor) dise√±ado para analizar petabytes de datos a gran velocidad.

- **¬øQu√© hice aqu√≠?** Lo us√© para explorar un dataset p√∫blico masivo (`london_bicycles`) que contiene millones de registros de viajes en bicicleta. BigQuery es perfecto para *leer* y *analizar* estos vol√∫menes gigantescos que matar√≠an a una base de datos normal.

### üóÑÔ∏è Google Cloud Storage (El Puente)

Es un servicio de almacenamiento de objetos (como un Google Drive vitaminado para apps).

- **¬øQu√© hice aqu√≠?** Actu√≥ como "zona de paso" (Staging Area). BigQuery no puede mandar datos directamente a Cloud SQL, as√≠ que usamos un Bucket de Cloud Storage para alojar los archivos CSV intermedios.

### üê¨ Google Cloud SQL (La Memoria Operativa)

Es un servicio de bases de datos relacionales totalmente administrado (en este caso, MySQL).

- **¬øQu√© hice aqu√≠?** Cre√© una instancia MySQL para recibir los datos procesados y simular un entorno donde una aplicaci√≥n web podr√≠a leer o escribir datos transaccionales (como registrar un nuevo viaje en tiempo real).

## 3. Desarrollo del Laboratorio (Paso a Paso)

### Fase 1: Extracci√≥n y An√°lisis en BigQuery

Acced√≠ al dataset p√∫blico de bicicletas de Londres. Utilic√© SQL para agrupar y contar los viajes por estaciones de inicio y fin.

Consulta ejecutada:

Se identificaron las estaciones con mayor tr√°fico.

> *Evidencia: Ejecuci√≥n de consultas en la interfaz de BigQuery.*
> 
> ![2025-11-30 15.52.51 console.cloud.google.com acc411512def.png](Fotos/673e5547cf59067b4b0c7419a3cfccd4cde0b145.png)

### Fase 2: Exportaci√≥n y Staging (ETL)

Los resultados de las consultas se exportaron como archivos CSV (`start_station_data.csv` y `end_station_data.csv`). Posteriormente, se cre√≥ un **Bucket** en Cloud Storage para alojar estos archivos, sirviendo como puente hacia la base de datos SQL.

> *Evidencia: Archivos CSV cargados en el Bucket de Cloud Storage.*
> 
> ![2025-11-30 15.55.24 console.cloud.google.com d51c1db89a41.png](Fotos/7fe5b3badb36db2300bf42a5a5b4b939766c4781.png)
> 
> ![2025-11-30 16.06.30 console.cloud.google.com 15fbc7b2afd9.png](Fotos/17a91376ef20549da78b1147fd229754a11ef68f.png)

### Fase 3: Aprovisionamiento de Infraestructura

Desplegu√© una instancia de **Cloud SQL (MySQL 8.0)** en la regi√≥n `us-east4`. Se configur√≥ como una instancia "Enterprise" con perfil de desarrollo para optimizar costos, garantizando conectividad segura mediante autenticaci√≥n de usuario root.

> *Evidencia: Instancia 'my-demo' operativa.*
> 
> ![2025-11-30 16.20.58 console.cloud.google.com 71adf551ac6a.png](Fotos/5039b00bf562184aa770c2755bfab710fbb09569.png)

### Fase 4: Definici√≥n de Esquema y Carga de Datos

Mediante **Cloud Shell**, me conect√© a la instancia MySQL y defin√≠ el esquema de la base de datos (DDL):

```
CREATE DATABASE bike;
USE bike;
CREATE TABLE london1 (start_station_name VARCHAR(255), num INT);
CREATE TABLE london2 (end_station_name VARCHAR(255), num INT);
```

Posteriormente, utilic√© la funci√≥n de **Importaci√≥n** de Cloud SQL para inyectar los datos desde el Bucket hacia estas tablas.

> *Evidencia: Estructura de tablas creada v√≠a terminal.*
> 
> ![2025-11-30 16.27.08 console.cloud.google.com 1ef58629a2b3.png](Fotos/0f24b0deef2dc018715562d625e3e6a1032c7afc.png)

> *Evidencia: Proceso de importaci√≥n desde Cloud Storage.*
> 
> ![2025-11-30 16.25.47 console.cloud.google.com a36923d95bde.png](Fotos/639aef72fa53fe5da2db22ca99a88df9efa8844c.png)
> 
> ![2025-11-30 16.26.33 console.cloud.google.com e5443f6ad87a.png](Fotos/7c38c5ee47cefba2f903886de3ed25c5267af098.png)

## 4. Cheat Sheet: SQL B√°sico Aprendido

Durante el laboratorio, se utilizaron comandos fundamentales del Lenguaje de Consulta Estructurado (SQL):

| **Comando**  | **Explicaci√≥n Humana**                 | **Ejemplo del Lab**                                         |
| ------------ | -------------------------------------- | ----------------------------------------------------------- |
| **SELECT**   | "Dame estos datos..."                  | `SELECT start_station_name...`                              |
| **FROM**     | "...de esta tabla/lugar"               | `FROM bigquery-public-data...`                              |
| **WHERE**    | "Pero solo si cumplen esta condici√≥n"  | `WHERE num > 100000`                                        |
| **GROUP BY** | "Junta los repetidos en uno solo"      | Agrupar por nombre de estaci√≥n para contar viajes.          |
| **ORDER BY** | "Ord√©nalos de mayor a menor"           | `ORDER BY num DESC`                                         |
| **UNION**    | "Pega los resultados de dos consultas" | Unir estaciones de inicio y fin en una sola lista.          |
| **DELETE**   | "Borra esto"                           | Eliminar los encabezados del CSV que se colaron como datos. |

## 5. An√°lisis de Seguridad: ¬øC√≥mo protegemos esto?

*Pregunta cr√≠tica de ingenier√≠a: En un entorno real, ¬øc√≥mo aseguramos este flujo?*

Si esto fuera producci√≥n, aplicar√≠amos las siguientes capas de defensa:

1. **Principio de M√≠nimo Privilegio (IAM):**
   
   - No usar el usuario `root` de la base de datos para las aplicaciones. Crear usuarios espec√≠ficos con permisos limitados (solo `SELECT` o `INSERT`).
   
   - La cuenta de servicio que hace la importaci√≥n solo debe tener permiso de `Storage Object Viewer` en el Bucket espec√≠fico, no en todo el proyecto.

2. **Seguridad de Red (VPC):**
   
   - **IP Privada:** La instancia Cloud SQL no deber√≠a tener IP p√∫blica (como ten√≠a en el lab). Deber√≠a ser accesible solo desde dentro de la red privada de Google (VPC) para evitar ataques desde internet.
   
   - **Cloud SQL Auth Proxy:** Para conectarnos desde nuestra m√°quina, usar√≠amos el Auth Proxy, que crea un t√∫nel encriptado y seguro sin exponer la base de datos.

3. **Encriptaci√≥n:**
   
   - Los datos en **reposo** (guardados en el disco de Google) ya est√°n encriptados por defecto.
   
   - Los datos en **tr√°nsito** (mientras viajan del Bucket a SQL) viajan por la red interna de Google, protegidos por TLS.

4. **VPC Service Controls:**
   
   - Crear un per√≠metro de seguridad que impida que los datos del Bucket o de BigQuery sean copiados a proyectos externos no autorizados (protecci√≥n contra exfiltraci√≥n de datos).

## 6. Conclusi√≥n

Este laboratorio demostr√≥ el ciclo de vida de los datos en la nube: **An√°lisis Masivo (BigQuery) -> Persistencia (Storage) -> Operaci√≥n (Cloud SQL)**. Se valid√≥ la capacidad de Google Cloud para integrar servicios heterog√©neos mediante est√°ndares abiertos como SQL y CSV, permitiendo mover informaci√≥n valiosa desde un almac√©n de "Big Data" hacia sistemas transaccionales listos para el consumo de aplicaciones.
